{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLM-R Sentence Level Tasks Basic Fine-Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UX_9phbzvS-w"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimashiRathnayake/CMCS-Text-Classification/blob/main/Basic_Fine_Tuning/XLM_R_Sentence_Level_Tasks_Basic_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjz_B0ExMG-i"
      },
      "source": [
        "## Fine Tune XLM-R \n",
        "Humor Detection & Hate speech Detection of Sinhala-English Code-Mixed Data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU Device name\")\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "n0NGw_djgHjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "50e43d3d-0ffd-4fa6-9bef-e81c7da14d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device name\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83BIF6GkMOgX"
      },
      "source": [
        "### **Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttEdhhiXzLV4"
      },
      "source": [
        "**User Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-dOwN7izK9c"
      },
      "source": [
        "technique = \"sentiment\" #@param [\"humor\", \"hate speech\", \"sentiment\"]\n",
        "experiment_no = \"1\" #@param [] {allow-input: true}\n",
        "oversample_dataset = False #@param {type:\"boolean\"}\n",
        "over_sampling_technique = \"ROS\" #@param [\"\", \"ROS\",\"ADASYN\", \"SMOTE\", \"BorderlineSMOTE\"]\n",
        "sampling_strategy = \"1:0.25:0.25\" #@param [] {allow-input: true}\n",
        "random_state = 41 #@param\n",
        "\n",
        "if technique == \"humor\" :\n",
        "  NO_OUTPUT_LAYERS = 2\n",
        "  tag_set = [\"Humorous\", \"Non-Humorous\"]\n",
        "elif technique == \"hate speech\":\n",
        "  NO_OUTPUT_LAYERS = 3\n",
        "  tag_set = [\"Abusive\", \"Hate-Inducing\", \"Not offensive\"]\n",
        "else:\n",
        "  NO_OUTPUT_LAYERS = 4\n",
        "  tag_set = [\"Positive\", \"Negative\", \"Neutral\", \"Conflict\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJd03ixfefB"
      },
      "source": [
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8TuP3plzhYD"
      },
      "source": [
        "**Folder Paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0l0Ry7zkCr"
      },
      "source": [
        "dataset_path = \"/content/drive/Shareddrives/FYP/corpus/Ã§ompleted_draft.csv\"\n",
        "model_save_path = \"/content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/\"+technique+\"/\"+experiment_no"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEbnAyepy4Bp"
      },
      "source": [
        "**Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzofSf7qwUjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6178779a-cc87-4758-bde1-ca6ec0fd4a7c"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets\n",
        "# !pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNDBKaShv_EH"
      },
      "source": [
        "import re\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, TrainingArguments, Trainer, AdamW, get_scheduler, EarlyStoppingCallback\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "import seaborn as sns\n",
        "from datasets import load_metric\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGy9gk5_w-37",
        "outputId": "aef94df8-c159-4f8a-90f7-63a1de7ea79f"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dui-e7Gz2w-R"
      },
      "source": [
        "### **Oversampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94nmLCkX2v6r"
      },
      "source": [
        "def apply_oversampling(x, y):\n",
        "\n",
        "  (unique, counts) = np.unique(y, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution Without Oversampling\", counts)\n",
        "\n",
        "  # define oversampling strategy\n",
        "  if (over_sampling_technique == \"\"):\n",
        "    return x, y\n",
        "  elif (over_sampling_technique == \"ROS\"):\n",
        "    if (technique==\"humor\"):\n",
        "      oversample = RandomOverSampler(sampling_strategy = float(sampling_strategy))\n",
        "    else:\n",
        "      sampling_ratio = sampling_strategy.split(\":\");\n",
        "      oversample = RandomOverSampler(sampling_strategy = {\n",
        "          0:int(counts[0]*float(sampling_ratio[0])), \n",
        "          1:int(counts[0]*float(sampling_ratio[1])), \n",
        "          2:int(counts[0]*float(sampling_ratio[2]))\n",
        "          })\n",
        "  elif (over_sampling_technique == \"ADASYN\"):\n",
        "    oversample = ADASYN(sampling_strategy=\"minority\")\n",
        "  elif (over_sampling_technique == \"SMOTE\"):\n",
        "    oversample = SMOTE()\n",
        "  elif (over_sampling_technique == \"BorderlineSMOTE\"):\n",
        "    oversample = BorderlineSMOTE()\n",
        "\n",
        "  # fit and apply the transform\n",
        "  X_over, y_over = oversample.fit_resample(x, y)\n",
        "\n",
        "  (unique, counts) = np.unique(y_over, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution After Oversampling\", counts)\n",
        "\n",
        "  return X_over, y_over"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLhb8qPCsVr9"
      },
      "source": [
        "### **Load & Preprocess Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai_G9OEMt2iF"
      },
      "source": [
        "def preprocess_texts(sentences):\n",
        "  sentences = [re.sub(r'http\\S+','',s) for s in sentences]\n",
        "  sentences = [s.replace('#','') for s in sentences]\n",
        "  sentences = [\"[CLS] \" + s + \" [SEP]\" for s in sentences]\n",
        "  return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YTNMEO4sUFw"
      },
      "source": [
        "all_data = pd.read_csv(dataset_path)\n",
        "\n",
        "if (technique == \"humor\"):\n",
        "  all_data = all_data[['Sentence', 'Humor']]\n",
        "elif (technique == \"hate speech\"):\n",
        "  all_data = all_data[['Sentence', 'Hate_speech']]\n",
        "else:\n",
        "  all_data = all_data[['Sentence', 'Sentiment']]\n",
        "\n",
        "all_data.columns = ['Sentence', 'Label']\n",
        "all_data['Label'], uniq = pd.factorize(all_data['Label'])\n",
        "\n",
        "X = all_data['Sentence'].values.tolist()\n",
        "y = all_data['Label'].values.tolist()\n",
        "\n",
        "# X = preprocess_texts(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZLIxGtZzAxW"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if oversample_dataset:\n",
        "  X_train = np.array(X_train).reshape(-1, 1)\n",
        "  X_train, y_train = apply_oversampling(X_train, y_train)\n",
        "  X_train = [x[0] for x in X_train.tolist()]\n",
        "# y_train = y_train.tolist()"
      ],
      "metadata": {
        "id": "YXuDWejX0eL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPVtYGe-aiqR"
      },
      "source": [
        "##### **Preprocess Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENzyR3O6ahPv"
      },
      "source": [
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\", do_lower_case=True) #######################################################uncased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q5BljjzbKS_"
      },
      "source": [
        "encoded_X_train = tokenizer(X_train, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "encoded_X_test = tokenizer(X_test, truncation=True, padding=True, max_length=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ36Nr1mbjk8"
      },
      "source": [
        "class DatasetObject(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DatasetObject(encoded_X_train, y_train)\n",
        "test_dataset = DatasetObject(encoded_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z8jK1iSwavn"
      },
      "source": [
        "train_sampler = RandomSampler(train_dataset)\n",
        "validation_sampler = SequentialSampler(test_dataset)\n",
        "train_loader = DataLoader(train_dataset, sampler=train_sampler , batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, sampler=validation_sampler , batch_size=BATCH_SIZE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYK-Ax5INrYU"
      },
      "source": [
        "### **Fine-Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e-V4t_dREav"
      },
      "source": [
        "#### **Initialize the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdW_oSQEft7g",
        "outputId": "d62200e0-4145-46b1-c7b0-1c21775f1efb"
      },
      "source": [
        "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=NO_OUTPUT_LAYERS)\n",
        "model.cuda()\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47WrmTxGMx8-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad7d0524-cdae-4a2c-e713-a348ccbff130"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbBk4Z7oECtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146b7d8f-c590-407e-d343-d379675276c9"
      },
      "source": [
        "import gc\n",
        "# del all_data, encoded_X_train, encoded_X_test, X_train, X_test, tokenizer, DatasetObject\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L583oCwfvgiR"
      },
      "source": [
        "#### **Fine-tuning in PyTorch with the Trainer API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hslUWjdO2mg6"
      },
      "source": [
        "##### **Fine-tune & Test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgEPDn1_yIwe"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"f1\")\n",
        "    metric4 = load_metric(\"accuracy\")\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    macro_precision = metric1.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"]\n",
        "    macro_recall = metric2.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"]\n",
        "    macro_f1 = metric3.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\":accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"macro_f1\": macro_f1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI63-kjFvni-"
      },
      "source": [
        "# Default Hyperparameters\n",
        "# training_args = TrainingArguments(\"test_trainer\") \n",
        "# learning_rate=5e-5, batch_size=8,  weight_decay=0, num_train_epochs=3\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate = LEARNING_RATE,\n",
        "    per_device_train_batch_size = BATCH_SIZE,\n",
        "    per_device_eval_batch_size = BATCH_SIZE,\n",
        "    output_dir = model_save_path,\n",
        "    num_train_epochs = EPOCHS,\n",
        "    metric_for_best_model=\"eval_macro_f1\",\n",
        "    load_best_model_at_end=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llV3iiwDsRso"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model = model, \n",
        "    args = training_args, \n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset,\n",
        "    compute_metrics = compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUzsMRnQsSqm"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX7ezOnK2rvM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f209b4d6-4c6c-4942-def6-fa4be6b31572"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 12166\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2286\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2286' max='2286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2286/2286 59:37, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.694349</td>\n",
              "      <td>0.701923</td>\n",
              "      <td>0.709078</td>\n",
              "      <td>0.701923</td>\n",
              "      <td>0.703068</td>\n",
              "      <td>0.472729</td>\n",
              "      <td>0.485939</td>\n",
              "      <td>0.477476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.595435</td>\n",
              "      <td>0.754438</td>\n",
              "      <td>0.765133</td>\n",
              "      <td>0.754438</td>\n",
              "      <td>0.753783</td>\n",
              "      <td>0.541857</td>\n",
              "      <td>0.523426</td>\n",
              "      <td>0.524900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.562000</td>\n",
              "      <td>0.609634</td>\n",
              "      <td>0.778107</td>\n",
              "      <td>0.786190</td>\n",
              "      <td>0.778107</td>\n",
              "      <td>0.777761</td>\n",
              "      <td>0.556107</td>\n",
              "      <td>0.553365</td>\n",
              "      <td>0.550268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.446200</td>\n",
              "      <td>0.564531</td>\n",
              "      <td>0.790680</td>\n",
              "      <td>0.790312</td>\n",
              "      <td>0.790680</td>\n",
              "      <td>0.788603</td>\n",
              "      <td>0.552920</td>\n",
              "      <td>0.554813</td>\n",
              "      <td>0.551889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.446200</td>\n",
              "      <td>0.596185</td>\n",
              "      <td>0.798077</td>\n",
              "      <td>0.795871</td>\n",
              "      <td>0.798077</td>\n",
              "      <td>0.795641</td>\n",
              "      <td>0.683796</td>\n",
              "      <td>0.583107</td>\n",
              "      <td>0.596241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.327200</td>\n",
              "      <td>0.654966</td>\n",
              "      <td>0.801775</td>\n",
              "      <td>0.804043</td>\n",
              "      <td>0.801775</td>\n",
              "      <td>0.801904</td>\n",
              "      <td>0.711875</td>\n",
              "      <td>0.639401</td>\n",
              "      <td>0.657265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-381\n",
            "Configuration saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-381/config.json\n",
            "Model weights saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-381/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-762\n",
            "Configuration saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-762/config.json\n",
            "Model weights saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-762/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1143\n",
            "Configuration saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1143/config.json\n",
            "Model weights saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1143/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1524\n",
            "Configuration saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1524/config.json\n",
            "Model weights saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1524/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1905\n",
            "Configuration saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1905/config.json\n",
            "Model weights saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-1905/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-2286\n",
            "Configuration saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-2286/config.json\n",
            "Model weights saved in /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-2286/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/Shareddrives/FYP/Humor_HateSpeech_detection/XLMR/sentiment/1/checkpoint-2286 (score: 0.6572647652825141).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2286, training_loss=0.4978538339636562, metrics={'train_runtime': 3578.6169, 'train_samples_per_second': 20.398, 'train_steps_per_second': 0.639, 'total_flos': 4801599870971904.0, 'train_loss': 0.4978538339636562, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYCFMo-_karm"
      },
      "source": [
        "**Test the fine-tuned model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcv3yEmwFpx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1418ebde-c423-43e6-91af-567362cad517"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [43/43 00:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 6.0,\n",
              " 'eval_accuracy': 0.8017751479289941,\n",
              " 'eval_f1': 0.8019036629624959,\n",
              " 'eval_loss': 0.6549655795097351,\n",
              " 'eval_macro_f1': 0.6572647652825141,\n",
              " 'eval_macro_precision': 0.7118746106700379,\n",
              " 'eval_macro_recall': 0.6394008390605737,\n",
              " 'eval_precision': 0.8040434184713193,\n",
              " 'eval_recall': 0.8017751479289941,\n",
              " 'eval_runtime': 21.1625,\n",
              " 'eval_samples_per_second': 63.887,\n",
              " 'eval_steps_per_second': 2.032}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "9ZgJgh5Sch_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "hjCNA_Ixn89J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_set = {'Sentence': X_test,\n",
        "#         'Label':predictions.label_ids,\n",
        "#         'Prediction':preds}\n",
        "  \n",
        "# # Create DataFrame\n",
        "# df = pd.DataFrame(test_set)"
      ],
      "metadata": {
        "id": "ssTI0FG1oKpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "R0vU4ku0pAZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"/content/drive/Shareddrives/FYP/final_models/xlmr-st/hate\")"
      ],
      "metadata": {
        "id": "23n8yQBdtbMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjpu4loFOhF-"
      },
      "source": [
        "##### **Hyperparameter Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq_MOrsM8ugi"
      },
      "source": [
        "# args = TrainingArguments(\n",
        "#     \"test-glue\",\n",
        "#     evaluation_strategy = \"epoch\",\n",
        "#     save_strategy = \"epoch\",\n",
        "#     learning_rate=LEARNING_RATE,\n",
        "#     per_device_train_batch_size=BATCH_SIZE,\n",
        "#     per_device_eval_batch_size=BATCH_SIZE,\n",
        "#     num_train_epochs=EPOCHS,\n",
        "#     weight_decay=0.01,\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model=\"eval_macro_f1\",\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsAB0QwAOjp9"
      },
      "source": [
        "# def my_hp_space(trial):\n",
        "#     return {\n",
        "#         # \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True),\n",
        "#         \"num_train_epochs\": trial.suggest_discrete_uniform(\"num_train_epochs\", 1, 5, 1),\n",
        "#         # \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
        "#         # \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32, 64]),\n",
        "#     }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_B7-8AGOlhu"
      },
      "source": [
        "# trainer = Trainer(\n",
        "#     model_init=model_init,\n",
        "#     args=args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=test_dataset,\n",
        "#     # tokenizer=tokenizer,\n",
        "#     compute_metrics=compute_metrics\n",
        "# )\n",
        "\n",
        "# best_run = trainer.hyperparameter_search(n_trials=5, direction=\"maximize\", hp_space=my_hp_space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX_9phbzvS-w"
      },
      "source": [
        "#### **Fine tuning with native PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f_2f-ifTkas"
      },
      "source": [
        "**Fine-tune the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YupLb6tQvCt"
      },
      "source": [
        "# def epoch_time(start_time, end_time):\n",
        "#   elapsed_time = end_time - start_time\n",
        "#   elapsed_mins = int(elapsed_time / 60)\n",
        "#   elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "#   return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exnw9_AAPMMI"
      },
      "source": [
        "# # apply different hyperpameters for specific parameter groups\n",
        "# # param_optimizer = list(model.named_parameters())\n",
        "\n",
        "# # optimizer_grouped_parameters = [\n",
        "# #     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "# #      'weight_decay_rate': 0.01},\n",
        "# #     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "# #      'weight_decay_rate': 0.0}\n",
        "# # ]\n",
        "# # optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n",
        "# optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rCA2AEoB3HU"
      },
      "source": [
        "# train_loss_set = []\n",
        "# num_training_steps = EPOCHS * len(train_loader)\n",
        "# progress_bar = tqdm(range(num_training_steps))\n",
        "# model.train()\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#   start_time = time.time()\n",
        "\n",
        "#   tr_loss = 0\n",
        "#   nb_tr_steps = 0\n",
        "  \n",
        "#   for batch in train_loader:\n",
        "\n",
        "#     batch = {k: v.to(device) for k, v in batch.items()}\n",
        "#     outputs = model(**batch)\n",
        "#     loss = outputs.loss\n",
        "#     loss.backward()\n",
        "\n",
        "#     optimizer.step()\n",
        "#     optimizer.zero_grad()\n",
        "#     progress_bar.update(1)\n",
        "\n",
        "#     train_loss_set.append(loss.item())    \n",
        "    \n",
        "#     tr_loss += loss.item()\n",
        "#     nb_tr_steps += 1\n",
        "\n",
        "#   end_time = time.time()\n",
        "\n",
        "#   print(epoch_time(start_time,end_time))\n",
        "#   print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taSFo4N7Tf0J"
      },
      "source": [
        "**Validate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiYHmez4S90U"
      },
      "source": [
        "# accuracy = load_metric(\"accuracy\")\n",
        "# precision = load_metric(\"precision\")\n",
        "# recall = load_metric(\"recall\")\n",
        "# f1 = load_metric(\"f1\")\n",
        "# macro_precision = load_metric(\"precision\")\n",
        "# macro_recall = load_metric(\"recall\")\n",
        "# macro_f1 = load_metric(\"f1\")\n",
        "\n",
        "# model.eval()\n",
        "# for batch in test_loader:\n",
        "#     batch = {k: v.to(device) for k, v in batch.items()}\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**batch)\n",
        "\n",
        "#     logits = outputs.logits\n",
        "#     predictions = torch.argmax(logits, dim=-1)\n",
        "#     accuracy.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     macro_precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     macro_recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     macro_f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "# print(accuracy.compute())\n",
        "# print(precision.compute(average=\"weighted\"))\n",
        "# print(recall.compute(average=\"weighted\"))\n",
        "# print(f1.compute(average=\"weighted\"))\n",
        "# print(\"macro averages:\")\n",
        "# print(macro_precision.compute(average=\"macro\"))\n",
        "# print(macro_recall.compute(average=\"macro\"))\n",
        "# print(macro_f1.compute(average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZDYa5WdkQzO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}